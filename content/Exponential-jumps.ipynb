{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential jumps: Reservoir sampling with much fewer random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following algorithm can be used to generate a random sample from a stream of weighted items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reservoir(stream):\n",
    "    R = None\n",
    "    T = 0\n",
    "    for i, w in stream:\n",
    "        K = np.random.uniform(0,1) ** (1.0/w)\n",
    "        if K > T:\n",
    "            T = K\n",
    "            R = i\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a pretty famous algorithm due to Eframidis and Spirakis (2006). In that same paper they introduce a less well-known algorith, that I thought I'd describe a bit. The idea is to reduce the number of random number's needed to generate a sample. `weighted_reservoir` requires $\\mathcal{O}(n)$ random numbers of a stream of length $n$. The following algorithm, requires an expected number of samples in $\\mathcal{O}(\\log n)$. So *way* fewer. Here is the algorith, it's called the exponential jumps algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expjump(stream):\n",
    "    R = None\n",
    "    logT = -np.inf\n",
    "    S = 0.0\n",
    "    J = 0.0\n",
    "    for i, w in stream:\n",
    "        if S + w < J:\n",
    "            S += w\n",
    "        else:\n",
    "            R = i\n",
    "            S = 0.0\n",
    "            # Update threshold\n",
    "            logT = np.log(np.random.uniform(np.exp(logT * w), 1)) / w\n",
    "            # Exponential jump\n",
    "            J = np.log(np.random.uniform(0,1))/logT\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4670047  0.01406817 0.28790651 0.05745718 0.17356344]\n",
      "[0.46713  0.0141   0.289655 0.05697  0.172145]\n",
      "err: 0.0019056164273275576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 5\n",
    "pp = np.random.uniform(0, 1, size=n)\n",
    "s = list(enumerate(pp))\n",
    "\n",
    "p = pp/pp.sum()\n",
    "\n",
    "reps = 200000\n",
    "#print(weighted_reservoir(s))\n",
    "q = np.zeros(n)\n",
    "for _ in range(1,1+reps):\n",
    "    q[expjump(s)] += 1 / reps\n",
    "print(p)\n",
    "print(q)\n",
    "\n",
    "print('err:', 0.5 * np.abs(p-q).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proof of correctness is seems pretty simple.\n",
    "\n",
    "(Efraimidis & Spirakis, 2006) Weighted random sampling with a reservoir\n",
    "file:///home/timv/.skid/marks/EfraimidisSpirakis05weighted.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why `expjumps` works\n",
    "\n",
    "The way we're going to understand why this algorithm works is by showing that it\n",
    "simulates the first algorithm.\n",
    "\n",
    "### Part 1: The \"exponential jump\"\n",
    "\n",
    "The probability that we advance from the current position $c$ to some future\n",
    "position $i$ is equal to\n",
    "\n",
    "$$\n",
    "p\\left( \\sum_{j=c}^{i-1} w_j < J \\le \\sum_{j=c}^{i} w_j \\right)\n",
    "$$\n",
    "\n",
    "Let $\\ell=\\sum_{j=c}^{i-1} w_j$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    " &=& p\\left(               \\ell < \\frac{\\log(U)}{\\log(T)} \\le \\ell + w_i         \\right) \\\\\n",
    " &=& p\\left(       \\log(T) \\ell < \\log(U)         \\le \\log(T) (\\ell + w_i)       \\right) \\\\\n",
    " &=& p\\left( \\exp(\\log(T) \\ell) < U               \\le \\exp(\\log(T) (\\ell + w_i)) \\right) \\\\\n",
    " &=& p\\left(           T^{\\ell} < U               \\le T^{\\ell + w_i} \\right) \\\\\n",
    " &=& T^{\\ell + w_i} - T^\\ell\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "XXX: looks backwards, p[a < X <= b] = cdf(b) - cdf(a)\n",
    "\n",
    "Which is equivalent to the ordinary version of the algorithm:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "&& \\!\\!\\!\\!\\!\\!\\!\\! p\\left( \\text{start at $c$ and only $i$ goes in $R$} \\right) \\\\\n",
    "&=& p\\left( \\text{$i$ goes in $R$} \\right) \\prod_{k=c}^{i-1} p\\left( \\text{$k$ does not go in $R$} \\right) \\\\\n",
    "&=& p\\left( U_i^{1/w_i} > T \\right) \\prod_{k=c}^{i-1} p\\left( U_k^{1/w_k} \\le T \\right) \\\\\n",
    "&=& (1 - T^{w_i}) \\prod_{k=c}^{i-1} T^{w_k} \\\\\n",
    "&=& (1 - T^{w_i}) \\cdot T^{\\sum_{j=c}^{i-1} w_j} \\\\\n",
    "&=& (1 - T^{w_i}) \\cdot T^{\\ell} \\\\\n",
    "&=& T^{\\ell} - T^{w_i} T^{\\ell} \\\\\n",
    "&=& T^\\ell - T^{\\ell + w_i}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "### Part 2: Where did $T = \\textrm{Uniform}(T^{w_i}, 1)^{1 / w_i}$ come from?\n",
    "\n",
    "At a high level, the reason this expression is sort of complicated is because\n",
    "$T$ is conditioned on the event $(i \\in R)$.\n",
    "\n",
    "Now, let's work out that distribution:\n",
    "\n",
    "For notational simplify, I'll to suppress the dependence on $i$, so $K = k_i =\n",
    "U_i^{1/w_i}$ and $w = w_i$.\n",
    "\n",
    "Let's derive an inverse CDF generator conditioned on $(i \\in R)$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "p\\left( K \\le x \\mid i \\in R \\right)\n",
    "&=& p\\left( K \\le x \\mid K > T \\right) \\\\\n",
    "&=& p\\left( U^{1/w} \\le x \\mid U^{1/w} > T \\right) \\\\\n",
    "&=& p\\left( U \\le X^w \\mid U > T^w \\right)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Apply the definition of conditional probability and shift the focus to the\n",
    "uniform variate U because we place in a nice cozy position between the\n",
    "inequalities.\n",
    "\n",
    "$$\n",
    "   = \\frac{p\\left( T^w < U \\le X^w \\right) }{ p\\left( U > T^w \\right) }\n",
    "$$\n",
    "\n",
    "Solve for the numerator and denominator given $U \\sim \\textrm{Uniform}(0,1)$,\n",
    "\n",
    "$$\n",
    "   = \\frac{X^w - T^w}{1-T^w}\n",
    "$$\n",
    "\n",
    "To apply the inverse CDF method, we solve for the target RV, $X$, in\n",
    "terms of $U$.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "                             U &=& \\frac{X^w - T^w}{1-T^w} \\\\\n",
    "               U \\cdot (1-T^w) &=& (X^w - T^w)             \\\\\n",
    "         U \\cdot (1-T^w) + T^w &=& X^w                     \\\\\n",
    " (U \\cdot (1-T^w) + T^w)^{1/w} &=& X\n",
    "\\end{eqnarray*}\n",
    "\n",
    "In other words, $X = \\textrm{Uniform}(T^w, 1)^{1/w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
